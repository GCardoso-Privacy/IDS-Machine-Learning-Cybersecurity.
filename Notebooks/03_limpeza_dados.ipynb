{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57da836-a57a-4701-ac78-a22c40adc588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> INICIANDO HIGIENIZA√á√ÉO DE DADOS (LOW RAM MODE) <<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Limpando Blocos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:43<00:00,  8.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ LIMPEZA CONCLU√çDA COM SUCESSO!\n",
      "üíæ Dataset pronto para IA salvo em: E:\\Estudos_Cybersecurity\\Datasets_Cybersecurity\\dataset_limpo.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CONFIGURA√á√ïES\n",
    "# =============================================================================\n",
    "INPUT_FILE = r\"E:\\Estudos_Cybersecurity\\Datasets_Cybersecurity\\dataset_treino_final.parquet\"\n",
    "OUTPUT_FILE = r\"E:\\Estudos_Cybersecurity\\Datasets_Cybersecurity\\dataset_limpo.parquet\"\n",
    "\n",
    "# Colunas que N√ÉO ajudam a detectar ataques (apenas identificam quem/quando)\n",
    "# Removemos para evitar que o modelo \"decore\" IPs espec√≠ficos (Overfitting)\n",
    "COLS_TO_DROP = [\n",
    "    'Flow ID', 'Flow_ID', \n",
    "    'Source IP', 'Source_IP', \n",
    "    'Destination IP', 'Destination_IP', \n",
    "    'Timestamp', \n",
    "    'SimillarHTTP', \n",
    "    'Unnamed: 0', 'origem_arquivo'\n",
    "]\n",
    "\n",
    "# Mapa para corrigir nomes estranhos de ataques (Encoding issues)\n",
    "LABEL_FIX = {\n",
    "    'Web Attack √Ø¬ø¬Ω Brute Force': 'Web Attack - Brute Force',\n",
    "    'Web Attack √Ø¬ø¬Ω XSS': 'Web Attack - XSS',\n",
    "    'Web Attack √Ø¬ø¬Ω Sql Injection': 'Web Attack - Sql Injection'\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# 2. PROCESSO DE LIMPEZA (CHUNKING)\n",
    "# =============================================================================\n",
    "def limpar_dataset():\n",
    "    print(\">>> INICIANDO HIGIENIZA√á√ÉO DE DADOS (LOW RAM MODE) <<<\")\n",
    "    \n",
    "    # Abre o arquivo em modo leitura de metadados\n",
    "    try:\n",
    "        parquet_file = pq.ParquetFile(INPUT_FILE)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao abrir arquivo: {e}\")\n",
    "        return\n",
    "\n",
    "    writer = None\n",
    "    total_chunks = parquet_file.num_row_groups\n",
    "    \n",
    "    for i in tqdm(range(total_chunks), desc=\"Limpando Blocos\"):\n",
    "        # 1. L√™ um peda√ßo do arquivo\n",
    "        df_chunk = parquet_file.read_row_group(i).to_pandas()\n",
    "        \n",
    "        # 2. Remove colunas identificadoras (IPs, IDs, etc)\n",
    "        # errors='ignore' porque algumas podem n√£o existir em todos os chunks\n",
    "        df_chunk.drop(columns=COLS_TO_DROP, inplace=True, errors='ignore')\n",
    "        \n",
    "        # 3. Corre√ß√£o de Labels (Caracteres estranhos)\n",
    "        if 'Label' in df_chunk.columns:\n",
    "            df_chunk['Label'] = df_chunk['Label'].replace(LABEL_FIX)\n",
    "            # Remove espa√ßos extras\n",
    "            df_chunk['Label'] = df_chunk['Label'].str.strip()\n",
    "        \n",
    "        # 4. TRATAMENTO DE INFINITOS E NULOS (CR√çTICO!)\n",
    "        # Seleciona apenas colunas num√©ricas\n",
    "        cols_numericas = df_chunk.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        # Substitui Infinito por NaN (para depois tratar tudo junto)\n",
    "        df_chunk[cols_numericas] = df_chunk[cols_numericas].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Preenche NaN com 0\n",
    "        # (Em fluxos de rede, geralmente dado ausente/nulo estat√≠stico equivale a zero)\n",
    "        df_chunk[cols_numericas] = df_chunk[cols_numericas].fillna(0)\n",
    "        \n",
    "        # 5. Salva o bloco limpo no novo arquivo\n",
    "        table = pa.Table.from_pandas(df_chunk)\n",
    "        \n",
    "        if writer is None:\n",
    "            writer = pq.ParquetWriter(OUTPUT_FILE, table.schema, compression='snappy')\n",
    "        \n",
    "        writer.write_table(table)\n",
    "        \n",
    "        # Limpa mem√≥ria RAM imediatamente\n",
    "        del df_chunk, table\n",
    "        gc.collect()\n",
    "\n",
    "    if writer:\n",
    "        writer.close()\n",
    "    \n",
    "    print(\"\\n‚úÖ LIMPEZA CONCLU√çDA COM SUCESSO!\")\n",
    "    print(f\"üíæ Dataset pronto para IA salvo em: {OUTPUT_FILE}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. EXECU√á√ÉO\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Remove arquivo antigo se existir para n√£o duplicar dados\n",
    "    if os.path.exists(OUTPUT_FILE):\n",
    "        try:\n",
    "            os.remove(OUTPUT_FILE)\n",
    "        except OSError:\n",
    "            print(\"‚ö†Ô∏è N√£o foi poss√≠vel remover o arquivo antigo. Reinicie o Kernel se der erro.\")\n",
    "            \n",
    "    limpar_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef29521e-8b33-427b-a2cf-49fc63d2f441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
